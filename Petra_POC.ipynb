{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-32bbd15de6ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#use for getting all column name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt'"
     ]
    }
   ],
   "source": [
    "#use for getting all column name\n",
    "import pandas as pd\n",
    "f=open('C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt')\n",
    "f.seek(0)\n",
    "a=f.readlines()\n",
    "a\n",
    "key=[]\n",
    "type=[]\n",
    "#Take one list that will go in report\n",
    "NotMatch_Column=[]\n",
    "\n",
    "st=a\n",
    "for i in st:\n",
    "    \n",
    "    for ch in ['MetaData:=',''':=StringType(18):',''''\\n',':','ConfigFileInfo','Query','Data','DATAQUALITY','SparkInputArguments','\\n']:  \n",
    "        \n",
    "        if ch in i:\n",
    "            i=i.replace(ch,'')\n",
    "            x=i.split('=')\n",
    "    key.append(x)\n",
    "#print(key)\n",
    "keynew=[]\n",
    "for i in range(0,len(key)):\n",
    "    p=key[i]\n",
    "    p=p[0]\n",
    "    keynew.append(p)\n",
    "keynew\n",
    "while '' in keynew:\n",
    "    keynew.remove('')\n",
    "print(keynew)\n",
    "#print(len(keynew))\n",
    "import pandas as pd\n",
    "df_data=pd.read_csv(\"C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv\")\n",
    "#@df3=pd.read_excel(\"C:\\\\Users\\\\29265\\\\Desktop\\\\data.xlsx\",sheetname='Sheet6')\n",
    "#df3\n",
    "\n",
    "data_col=list(df_data.columns)\n",
    "data_col\n",
    "insection=list(set(data_col) & set(keynew))\n",
    "insection\n",
    "if set(keynew) == set(insection):\n",
    "    print('passed')\n",
    "  \n",
    "    dic_notmatch_col={'Not_Matched_Column':NotMatch_Column}\n",
    "else:\n",
    "    NotMatch_Column=list(set(insection)-set(keynew))\n",
    "    dic_notmatch_col={'Not_Matched_Column':NotMatch_Column}\n",
    "#if false\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Errors:=Author:=Mriganka\\n',\n",
       " 'Errors:=CreatedDate:=2018-03-28\\n',\n",
       " 'Errors:=Version:=1.0\\n',\n",
       " 'Errors:=ModifiedDate:=2018-05-14\\n',\n",
       " 'Errors:=ModifiedBy:=Mriganka\\n',\n",
       " \"Errors:=ChangesHistory:=Changed CommercialName,OwnershipType,Status,District,Country,OutletType,RecordTypeName to Nullable fields defaulted with 'N/A'\\n\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write a python function to parse a log file and extract details of errors and warnings recorded into a separate file\n",
    "f=open('C:\\\\Users\\\\29265\\\\Desktop\\\\log.txt')\n",
    "f.seek(0)\n",
    "a=f.readlines()\n",
    "result1 = [i for i in a if i.startswith('Errors')]\n",
    "result2 = [i for i in a if i.startswith('warnings')]\n",
    "finalList = result1 + result2\n",
    "with open('your_file.txt', 'w') as f:\n",
    "    for item in finalList:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Name','Roll number','Age','Gender'])\n",
    "inputrecord=[]\n",
    "while(True):\n",
    "    print(\"Student info\")\n",
    "    total_num_of_students = input(\"enter student name:\")\n",
    "    inputrecord.append(total_num_of_students)\n",
    "    total_num_of_students = input(\"enter student roll:\")\n",
    "    inputrecord.append(total_num_of_students)\n",
    "    total_num_of_students = input(\"enter student age:\")\n",
    "    inputrecord.append(total_num_of_students)\n",
    "    total_num_of_students = input(\"enter student G:\")\n",
    "    inputrecord.append(total_num_of_students)\n",
    "    break\n",
    "\n",
    "df=df.T\n",
    "indexx=list(df.index)\n",
    "print(indexx)\n",
    "s1 = pd.Series(inputrecord, index=[indexx[0], indexx[1], indexx[2], indexx[3]])\n",
    "df=df.T\n",
    "result = df.append(s1, ignore_index=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter total number of students:5\n",
      "you entered 5 students\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-110630342f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstudent_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstudent_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;34m'rollno'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mstudent_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gender'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_num_of_students\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstudent_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Name :\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import re\n",
    "total_num_of_students = int(input(\"enter total number of students:\"))\n",
    "print (\"you entered %s students\" %total_num_of_students)\n",
    "student_info = {}\n",
    "student_data = [ 'rollno', 'age', 'gender']\n",
    "student_data['gender']=re.match\n",
    "for i in range(0,total_num_of_students):\n",
    "    student_name = input(\"Name :\")\n",
    "    student_info[student_name] = {}\n",
    "    for j in student_data:\n",
    "        student_info[student_name][j] = input(j)\n",
    "name = input(\"to find info enter valid student name\")\n",
    "if name in student_info.keys():\n",
    "    print (student_info[student_name])\n",
    "else:\n",
    "    print(\"please enter valid name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result2\n",
    "finalList = result1 + result2\n",
    "finalList\n",
    "with open('your_file.txt', 'w') as f:\n",
    "    for item in finalList:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3d5bd10e11ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#to get all dublicate value from primary key column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_count_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCustId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_count_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_count_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#columns=['value','count']\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#df_count_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\29265\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\29265\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\29265\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\29265\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\29265\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#to get all dublicate value from primary key column\n",
    "df_data=pd.read_csv(\"C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv\")\n",
    "df_count_val=df_data.CustId.value_counts()\n",
    "df_count_val=pd.DataFrame(df_count_val)#columns=['value','count']\n",
    "#df_count_val\n",
    "df_count_val_T=df_count_val.T\n",
    "#df_count_val_T\n",
    "dublicate_val=[]\n",
    "primarykeyduplicate_Count=[]\n",
    "d_count=[]\n",
    "for i in df_count_val_T.columns: \n",
    "    zzz=df_count_val_T[i]\n",
    "    if zzz[0]!=1:\n",
    "        #print(i)\n",
    "           dublicate_val.append(i)\n",
    "#if dublicate_val==null:\n",
    "len(dublicate_val)\n",
    "if len(dublicate_val)!=0:\n",
    "    print(dublicate_val)\n",
    "    for j in range(0,len(dublicate_val)):\n",
    "        a=list(df_count_val_T[dublicate_val[j]])\n",
    "        a=a[0]\n",
    "        ex_dic_df_dublicate={'PrimaryKey-CustID_Duplicate_Counts':dublicate_val[j],'Total Count':a}\n",
    "        primarykeyduplicate_Count.append(ex_dic_df_dublicate)\n",
    "else:\n",
    "    print('all record are unique in primary key column')\n",
    "primarykeyduplicate_Count\n",
    "pd.DataFrame(primarykeyduplicate_Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dublicate_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to get all col n type\n",
    "import string\n",
    "import re\n",
    "f=open('C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt')\n",
    "f.seek(0)\n",
    "a=f.readlines()\n",
    "a\n",
    "\n",
    "id = []\n",
    "for ln in a:\n",
    "    if ln.startswith(\"MetaData:=\"):\n",
    "        \n",
    "        id.append(ln[10:])\n",
    "#print(id)\n",
    "lt_dict={}\n",
    "for i in range(0,len(id)):\n",
    "    zz=id[i]\n",
    "    zz=zz.split(':=')\n",
    "    pp = re.sub('[\\n]', '', zz[2])\n",
    "    lt_dict[zz[0]]=pp\n",
    "print(lt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns list #data_col\n",
    "# lt_dict\n",
    "#keynew\n",
    "for i in range(0,len(keynew)):\n",
    "    for j in range(0,len(data_col)):\n",
    "        \n",
    "    \n",
    "    #print(keynew[i])\n",
    "    #print(lt_dict[keynew[i]])\n",
    "        if keynew[i]==data_col[j]:\n",
    "            type=lt_dict[keynew[i]]\n",
    "            total_count=list(df_data[keynew[i]])\n",
    "            \n",
    "            print(total_count)\n",
    "            #print(keynew[i])\n",
    "            print(df_data.shape[0])\n",
    "        #df_data[i]\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data1=pd.read_csv(\"C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv\")\n",
    "#df_count_val12=df_data1.SourceSystemId.value_counts()\n",
    "df_count_val12=df_data1['CustId'].isnull().sum()\n",
    "#df.isnull().sum()\n",
    "print(df_count_val12)\n",
    "df_data1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFileName(path):\n",
    "    \n",
    "    b=a.split('\\\\')\n",
    "    d=len(b)-1\n",
    "    f=b[d]\n",
    "    b=f.split('.')\n",
    "    return b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confi='C:\\\\Users\\\\29265\\\\Desktop\\\\Config_Dimension_Cust.txt'\n",
    "data='C:\\\\Users\\\\29265\\\\Desktop\\\\Data_Dimension_Cust.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keynew' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d57224463533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mNull_Value_Count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeynew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keynew' is not defined"
     ]
    }
   ],
   "source": [
    "#to get all columns wise null value count\n",
    "# columns list #data_col\n",
    "# lt_dict\n",
    "#keynew\n",
    "Null_Value_Count=[]\n",
    "\n",
    "for i in range(0,len(keynew)):\n",
    "    for j in range(0,len(data_col)):\n",
    "        \n",
    "    \n",
    "    #print(keynew[i])\n",
    "    #print(lt_dict[keynew[i]])\n",
    "        if keynew[i]==data_col[j]:\n",
    "            type=lt_dict[keynew[i]]\n",
    "            #print(type)\n",
    "            # | (type=='Nullable'):\n",
    "            if (type=='NonNullable'):\n",
    "                \n",
    "                #df_count_val12 should be equal to zero\n",
    "                df_count_val12=df_data[keynew[i]].isnull().sum()\n",
    "                if df_count_val12!=0:\n",
    "                    print(\"for column: '{}' total null count is :{}\".format(keynew[i],df_count_val12))\n",
    "                    \n",
    "                    ex_dic_df={'Column Name':keynew[i],\n",
    "                               'Null Count':df_count_val12\n",
    "                        \n",
    "                    }\n",
    "                   \n",
    "                    Null_Value_Count.append(ex_dic_df)\n",
    "                    #ex_dic_df[keynew[i]]=df_count_val12\n",
    "                 \n",
    "            '''   \n",
    "            if (type=='Nullable'):\n",
    "                \n",
    "                #df_count_val12 should be equal to zero\n",
    "                df_count_val12=df_data[keynew[i]].isnull().sum()\n",
    "                if df_count_val12!=0:\n",
    "                    print(\"for column: '{}' total null count is :{}\".format(keynew[i],df_count_val12))\n",
    "            '''      \n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dic_notmatch_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-69ca14cf90f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdfblank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf123\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_notmatch_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#df124=pd.DataFrame(ex_dic_df_dublicate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dic_notmatch_col' is not defined"
     ]
    }
   ],
   "source": [
    "# To print all null value in excel ,use #df123\n",
    "# to print all not match col,use this# NotMatch_Column\n",
    "#TO PRINT ALL DUBLICATE PRIMARY KEY VAL,USE dublicate_val\n",
    "c=[]\n",
    "dfblank=pd.DataFrame(c)\n",
    "df123=pd.DataFrame(dic_notmatch_col)\n",
    "#df124=pd.DataFrame(ex_dic_df_dublicate)\n",
    "\n",
    "df125=pd.DataFrame(Null_Value_Count)\n",
    "\n",
    "writer = pd.ExcelWriter('Petra_Report.xlsx', engine='xlsxwriter')\n",
    "\n",
    "dfblank.to_excel(writer, sheet_name='Summary_Report',startrow=2)\n",
    "\n",
    "df123.to_excel(writer, sheet_name='Sheet2',startrow=2)  # Default position, cell A1.\n",
    "df124.to_excel(writer, sheet_name='Sheet2',startcol=3,startrow=2)  # Default position, cell A1.\n",
    "df125.to_excel(writer, sheet_name='Sheet2', startcol=7,startrow=2)\n",
    "\n",
    "writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom openpyxl import load_workbook\\nimport xlsxwriter\\nwb = load_workbook(\\'C:\\\\Users\\\\29265\\\\Petra_Report.xlsx\\') \\nws = wb.get_sheet_by_name(\"Summary_Report\")\\n#use for loop to iterate file name\\nlink = \"Petra_Report.xlsx#sheet2!E5\"\\n#below code is to write link\\n#ws.write_url(\\'A2\\', link, string=\\'Python Home\\')\\nws.cell(row=2, column=1).hyperlink = (link)\\n\\nwb.save(\\'C:\\\\Users\\\\29265\\\\Petra_Report.xlsx\\')\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "wb = load_workbook('C:\\\\Users\\\\29265\\\\Petra_Report.xlsx') \n",
    "ws = wb.get_sheet_by_name(\"Summary_Report\")\n",
    "#use for loop to iterate file name\n",
    "link = \"Petra_Report.xlsx#sheet2!E5\"\n",
    "#below code is to write link\n",
    "#ws.write_url('A2', link, string='Python Home')\n",
    "ws.cell(row=2, column=1).hyperlink = (link)\n",
    "\n",
    "wb.save('C:\\\\Users\\\\29265\\\\Petra_Report.xlsx')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dic_notmatch_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-27a2e5bbb727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdfblank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf123\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic_notmatch_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#primarykeyduplicate_Count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#df124=pd.DataFrame(ex_dic_df_dublicate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dic_notmatch_col' is not defined"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "#d=pd.DataFrame({'b':[2,3]})\n",
    "\n",
    "#print(df134)\n",
    "c=[]\n",
    "dfblank=pd.DataFrame(c)\n",
    "df123=pd.DataFrame(dic_notmatch_col)\n",
    "#primarykeyduplicate_Count\n",
    "#df124=pd.DataFrame(ex_dic_df_dublicate)\n",
    "df124=pd.DataFrame(primarykeyduplicate_Count)\n",
    "dup_total_Count=df124['Total Count'].sum()\n",
    "#total_Count=df125['Null Count'].sum()\n",
    "df125=pd.DataFrame(Null_Value_Count)\n",
    "total_Count=df125['Null Count'].sum()\n",
    "f_p_status={'No Of Files Verified':1,\n",
    "            'No_Of Success':0,\n",
    "            'No_Of Failed':1\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "b=[]\n",
    "b.append(f_p_status)\n",
    "df_f_p_status=pd.DataFrame(b)\n",
    "#df_f_p_status.style.set_properties(subset=['No Of Files Verified','No_Of Success','No_Of Failed'], **{'width': '1000px'})\n",
    "df_f_p_status=df_f_p_status.T\n",
    "dict={'Config':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Config_Dimension_Cust\")',\n",
    "      'DataFile':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Data_Dimension_Cust\")',\n",
    "     'Not_Matched_Column':'',\n",
    "      'Dublicate_Counts_PK':dup_total_Count,\n",
    "     'NotNullable_Count':total_Count,\n",
    "     'Status':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Failed\")'\n",
    "     }\n",
    "a=[]\n",
    "a.append(dict)\n",
    "df134=pd.DataFrame(a)\n",
    "print(df134)\n",
    "writer = pd.ExcelWriter('Petra_Report.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df134.to_excel(writer, sheet_name='Summary_Report',startrow=0,index = False,startcol=0) \n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Summary_Report']\n",
    "worksheet.set_column('A:G', 20)\n",
    "worksheet.set_column('H:H', 20)\n",
    "# Add a header format.\n",
    "header_format = workbook.add_format({\n",
    "    'bold': True,\n",
    "'font_color': 'dark blue',\n",
    "    'text_wrap': False,\n",
    "    'valign': 'top',\n",
    "    'fg_color': '#D7E4BC',\n",
    "    'border': 1\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "# Write the column headers with the defined format.\n",
    "for col_num, value in enumerate(df134.columns.values):\n",
    "    worksheet.write(0, col_num , value, header_format)\n",
    "\n",
    "\n",
    "df123.to_excel(writer, sheet_name='Config_Dimension_Cust',startrow=2)  # Default position, cell A1.\n",
    "df124.to_excel(writer, sheet_name='Config_Dimension_Cust',startcol=3,startrow=2)  # Default position, cell A1.\n",
    "df125.to_excel(writer, sheet_name='Config_Dimension_Cust', startcol=7,startrow=2)\n",
    "\n",
    "df_f_p_status.to_excel(writer, sheet_name='Summary_Report',header=False,startcol=7) \n",
    "\n",
    "#d.to_excel(writer, sheet_name='Config_Dimension_Cust',startrow=1)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    =HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Failed\")\n",
      "Name: Status, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "#d=pd.DataFrame({'b':[2,3]})\n",
    "\n",
    "#print(df134)\n",
    "c=[]\n",
    "dfblank=pd.DataFrame(c)\n",
    "#df123=pd.DataFrame(dic_notmatch_col)\n",
    "#primarykeyduplicate_Count\n",
    "#df124=pd.DataFrame(ex_dic_df_dublicate)\n",
    "#df124=pd.DataFrame(primarykeyduplicate_Count)\n",
    "#dup_total_Count=df124['Total Count'].sum()\n",
    "#total_Count=df125['Null Count'].sum()\n",
    "#df125=pd.DataFrame(Null_Value_Count)\n",
    "#total_Count=df125['Null Count'].sum()\n",
    "f_p_status={'No Of Files Verified':1,\n",
    "            'No_Of Success':0,\n",
    "            'No_Of Failed':1\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "b=[]\n",
    "b.append(f_p_status)\n",
    "df_f_p_status=pd.DataFrame(b)\n",
    "#df_f_p_status.style.set_properties(subset=['No Of Files Verified','No_Of Success','No_Of Failed'], **{'width': '1000px'})\n",
    "df_f_p_status=df_f_p_status.T\n",
    "dict={'Config':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Config_Dimension_Cust\")',\n",
    "      'DataFile':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Data_Dimension_Cust\")',\n",
    "     'Not_Matched_Column':'',\n",
    "     # 'Dublicate_Counts_PK':dup_total_Count,\n",
    "    # 'NotNullable_Count':total_Count,\n",
    "     'Status':'=HYPERLINK(\"#Config_Dimension_Cust!A1\",\"Failed\")'\n",
    "     }\n",
    "a=[]\n",
    "a.append(dict)\n",
    "df134=pd.DataFrame(a)\n",
    "print(df134.Status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Petra_Report.xlsx', engine='xlsxwriter')\n",
    "df134.to_excel(writer, sheet_name='Sheet1', startrow=1, header=False)\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "worksheet.set_column('B:D', 20)\n",
    "# Add a header format.\n",
    "header_format = workbook.add_format({\n",
    "    'bold': True,\n",
    "    'text_wrap': False,\n",
    "    'valign': 'top',\n",
    "    'fg_color': '#D7E4BC',\n",
    "    'border': 1\n",
    "    \n",
    "})\n",
    "\n",
    "# Write the column headers with the defined format.\n",
    "for col_num, value in enumerate(df134.columns.values):\n",
    "    worksheet.write(0, col_num + 1, value, header_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10})\n",
    "header_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10, 'bold': True})\n",
    "\n",
    "worksheet.set_column('A:A', None, font_fmt)\n",
    "worksheet.set_row(0, None, header_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.core' has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-99878f4fc6df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Petra_Report.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlsxwriter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader_style\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf134\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Get the xlsxwriter workbook and worksheet objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas.core' has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('Petra_Report.xlsx', engine='xlsxwriter')\n",
    "pd.core.format.header_style = None\n",
    "df134.to_excel(writer, sheet_name='Sheet1', startrow=1, header=False)\n",
    "\n",
    "# Get the xlsxwriter workbook and worksheet objects.\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "font_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10})\n",
    "header_fmt = workbook.add_format({'font_name': 'Arial', 'font_size': 10, 'bold': True})\n",
    "\n",
    "worksheet.set_column('A:A', None, font_fmt)\n",
    "worksheet.set_row(0, None, header_fmt)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_Count=df125['Null Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=[]\n",
    "dfblank=pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfblank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_notmatch_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  a\n",
       "1  b\n",
       "2  3\n",
       "3  4"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt=['a','b',3,4]\n",
    "pd.DataFrame(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count_val12=df_data1['CustId'].isnull().sum()\n",
    "df_count_val12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TimeZone'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nullable'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt_dict['Country']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
