{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HEYRAMBO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Classifiation using NLP\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "reviews = load_files('txt_sentoken/')\n",
    "X,y = reviews.data,reviews.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickling the dataset\n",
    "with open('X.pickle','wb') as f:\n",
    "    pickle.dump(X,f)\n",
    "    \n",
    "with open('y.pickle','wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpickling dataset\n",
    "X_in = open('X.pickle','rb')\n",
    "y_in = open('y.pickle','rb')\n",
    "X = pickle.load(X_in)\n",
    "y = pickle.load(y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the corpus\n",
    "corpus = []\n",
    "for i in range(0, 2000):\n",
    "    review = re.sub(r'\\W', ' ', str(X[i])) ## Special Characters\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'^br$', ' ', review)\n",
    "    review = re.sub(r'\\s+br\\s+',' ',review) ##Space before and after special characters \n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review)\n",
    "    review = re.sub(r'^b\\s+', '', review)\n",
    "    review = re.sub(r'\\s+', ' ', review)\n",
    "    corpus.append(review)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the BOW model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features = 2000, min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "# Creating the Tf-Idf Model\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "text_train, text_test, sent_train, sent_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "# Training the classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(text_train,sent_train)\n",
    "\n",
    "\n",
    "# Testing model performance\n",
    "sent_pred = classifier.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(sent_test, sent_pred)\n",
    "\n",
    "\n",
    "# Saving our classifier\n",
    "with open('classifier.pickle','wb') as f:\n",
    "    pickle.dump(classifier,f)\n",
    "    \n",
    "# Saving the Tf-Idf model\n",
    "with open('tfidfmodel.pickle','wb') as f:\n",
    "    pickle.dump(vectorizer,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using our classifier\n",
    "with open('tfidfmodel.pickle','rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "    \n",
    "with open('classifier.pickle','rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "    \n",
    "sample = [\"You are a nice person man, have a good life\"]\n",
    "sample = tfidf.transform(sample).toarray()\n",
    "sentiment = clf.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie is not good\n"
     ]
    }
   ],
   "source": [
    " \n",
    "sample = [\"You are a nice person man, have a good life\"]\n",
    "sample = tfidf.transform([input()]).toarray()\n",
    "sentiment = clf.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base_dataset=pd.read_csv(\"C:\\\\Users\\\\HEYRAMBO\\\\Desktop\\\\Amazon_Unlocked_Mobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['Reviews'].head()\n",
    "base_dataset=base_dataset.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "x=[]\n",
    "for i in base_dataset['Reviews']:\n",
    "    testimonial = TextBlob(str(i))\n",
    "    x.append([testimonial.sentiment.subjectivity,testimonial.sentiment.polarity])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dataset['score']=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295878     [0.43571428571428567, 0.057738095238095255]\n",
       "182963                                      [1.0, 1.0]\n",
       "174890       [0.6666666666666666, -0.6999999999999998]\n",
       "14975                                      [1.0, -0.4]\n",
       "400                                         [0.3, 1.0]\n",
       "7589                                     [0.4875, 0.0]\n",
       "387974                     [0.18666666666666668, 0.19]\n",
       "341824        [0.7800000000000001, 0.9099999999999999]\n",
       "353448                                      [0.8, 0.4]\n",
       "228383                                     [1.0, 0.65]\n",
       "113627                                      [1.0, 1.0]\n",
       "377220                     [0.24999999999999997, 0.05]\n",
       "84754     [0.6132575757575758, -0.0064393939393939574]\n",
       "410460       [0.8288888888888889, 0.21703703703703703]\n",
       "366102                                      [0.6, 0.5]\n",
       "226720                     [0.35, 0.06000000000000001]\n",
       "261684        [0.463265306122449, 0.22346938775510203]\n",
       "113728                                      [0.0, 0.0]\n",
       "14921       [0.45454545454545453, 0.13636363636363635]\n",
       "61920         [0.33409090909090916, 0.262310606060606]\n",
       "333208        [0.7800000000000001, 0.9099999999999999]\n",
       "79868                                     [0.05, -0.2]\n",
       "8507                       [0.55, 0.41666666666666663]\n",
       "17361                                      [0.75, 0.8]\n",
       "111418                       [0.6000000000000001, 0.7]\n",
       "253273                                   [0.675, 0.65]\n",
       "361495                       [0.6000000000000001, 0.7]\n",
       "379108                                     [0.6, 0.25]\n",
       "268686                     [0.5416666666666666, 0.525]\n",
       "96749                                       [0.0, 0.0]\n",
       "                              ...                     \n",
       "220895        [0.6900000000000002, 0.8049999999999999]\n",
       "66515                       [0.5900000000000001, 0.45]\n",
       "207906     [0.7666666666666666, -0.012499999999999983]\n",
       "336334        [0.7800000000000001, 0.9099999999999999]\n",
       "110623                                      [0.0, 0.0]\n",
       "389005                                      [0.0, 0.0]\n",
       "208449                                 [0.5, -0.09375]\n",
       "162994      [0.38571428571428573, 0.31428571428571433]\n",
       "328244        [0.7333333333333333, 0.5333333333333333]\n",
       "395404        [0.8888888888888888, 0.5744444444444444]\n",
       "317109                                     [0.75, 0.8]\n",
       "329715        [0.6866666666666669, 0.7733333333333333]\n",
       "54751                      [0.30000000000000004, 0.35]\n",
       "205069                                     [0.4, -0.1]\n",
       "238999                   [0.315, 0.058333333333333334]\n",
       "211039                      [0.5, 0.29166666666666663]\n",
       "3874        [0.45454545454545453, 0.13636363636363635]\n",
       "174361      [0.48899572649572653, 0.17839209401709402]\n",
       "107921     [0.39999999999999997, -0.30000000000000004]\n",
       "155096    [0.26785714285714285, -0.024999999999999974]\n",
       "320505                                      [0.0, 0.0]\n",
       "22812       [0.5218181818181817, -0.00945454545454546]\n",
       "241075        [0.5041208791208791, 0.2745604395604396]\n",
       "3725          [0.5272727272727273, 0.5056818181818181]\n",
       "225869                      [0.75, 0.6333333333333333]\n",
       "153130      [0.6403846153846154, -0.14358974358974358]\n",
       "129650                                    [0.55, 0.25]\n",
       "329928                                      [0.0, 0.0]\n",
       "168421                                     [1.0, 0.78]\n",
       "281151     [0.3464285714285714, -0.002678571428571419]\n",
       "Name: score, Length: 100, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset['score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
